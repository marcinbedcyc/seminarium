# Wykorzystanie modeli TensorFlow na Raspberry Pi

### Opis
Analiza wykorzystywania wyuczonych modeli uczenia maszynowego na raspberry PI. Gromadzenie informacji na potrzebny pracy innżynierskiej.

### Konfiguracja Środowiska
Głównie będziemy pracować z `python`, dlatego rekomenduje instalacje środowiska wirtulanego, w którym będziemy trzymać wszystkie zainstalowane biblioteki przy pomocy `pip`. Dodatkowo poleca użycie `virtualnenvwrapper` aby trzymać wszystkie środowiska wirtualne na komputerze w jednym miejscu. Tutaj mogą wystąpić problemy z instalacją na urządzeniu Raspberry spowodowane słabą kompatybilno¶cią. U mnie zadziało zainstlowanie `virtualenvwrapper` w wersji 4.8.4  z podanie numeru wersji podczas instalacji(`pip install virtualenvwrapper` nie działało)): 
```
pip install virtualenvwrapper=="4.8.4"
```
Następnie musimy edytować plik `.bashrc` dodając nastepujące wpisy:
```
export WORKON_HOME=$HOME/.virtualenvs
VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3
VIRTUALENVWRAPPER_VIRTUALENV=~/.local/bin/virtualenv
source ~/.local/bin/virtualenvwrapper.sh # path to virtualenvwrapper.sh (różne w zależno¶ci od systemu)
```
Od teraz przy pomocy `mkvirtualenv example_name` możemy utworzyć nowe wirtualne środowisko, aby je aktywować należy wykonać `workon example_name`.

### Tensorflow Lite
Dostarcza narzędzia potrzebne to uruchomienia TensorFlow na urządzeniach mobilnych, IoT oraz urządzeniach osadzonych (z ang. embedded). 

##### 1. Na początek potrzebujemy modelu TensorFlow
Jest to struktura danych, która zawiera logikę i mechanizmy wyszkolnych sieci neuronwych. Taki model możemy sami wytrenować albo skorzystać z wytrenowanych już modeli.**TensorFlow Lite nie udostępnia narzędzi do szkolenia modeli**. Przykładowe wyćwiczone modele dostarczone przez TensorFlow to: 

	* Klasyfikacja obrazów
	* Wykrywanie obiektów
	* Inteligentne odpowiedzi
	* Pose estimation
	* Segmentation
	* Transfer stylu
	* Klasyfikacja tekstu
	* Pytania i odpowiedzi

	Skąd jeszcze czerpać modele: [TensorFlowHub](https://www.tensorflow.org/hub) . Przed skorzystanie należy przekonwertować te modele na format Lite.
	Modele również mogą zostać przetrenowane ponownie, jest to mniej złożona operacja niż wytrenowanie modelu od zera.

##### 2. Wykorzystaj to mądrze
TensorFlow Lite jest stworzone aby wykorzystać modele efektywnie na urządzeniach ograniczonych w moc obliczeniową i zasoby. Część tej efektywności możemy uzyskać poprzez stosowanie specjlanego formatu do przechowywaniu modelu.Konwersja jest obowiązkowa dla TensorFlow Lite. Konwersja powoduje zmianę rozmiaru, wproawdza optymalizacje, ale nie wywiera wpływu na dokładność. Aby przekonwertować model musimy użyć modułu TensorFlow(nie Lite):
```
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()
open("converted_model.tflite", "wb").write(tflite_model)
```

Konwertera również możemy użyć z poziomu linii poleceń:
```
tflite_convert --saved_model_dir=model  --output_file=model.tflite
```

Akcpetowalne wejście przez konwerter:
* 1.x models:
	* SavedModel directories
	* Frozen GraphDef (models generated by freeze_graph.py)
	* Keras HDF5 models
	* Models taken from a tf.Session
* 2.x models:
	* SavedModel directories
	* tf.keras models
	* Concrete functions

TensorFlow Lite wspiera ograniczoną liczbę opracji TensorFlow: [Ograniczenia](https://www.tensorflow.org/lite/guide/ops_compatibility) 

##### 3. Inference - wnioskowanie
Wnioskowanie na podstawie modelu t.zw. **Inference** - proces, który analizuje dane na podstawie modelu i zwraca przewidywania. Wyamgany jest model, interpreter oraz dane wejściowe. Interpreter jest to biblioteka, któe przyjmuje plik modelu, wykonuje opercję i definuje wynik. Dostarczone jest proste API interpretera na wiele platform: Java, Swift, Objective-C, C++ oraz Python. Skupmy się na ostatnim:
* TensorFlow: 
	```python
	import tensorflow as tf

	tf.lite.Interpreter(
		model_path=None, model_content=None, experimental_delegates=None
	)
	```
* TensorFlow Lite:
	```python
	import tflite_runtime.interpreter as tflite

	tflite.Interpreter(model_path=args.model_file)
	```

	Niektóre urządzenia wspierają akcelerację sprzętową dla operacji uczenia maszynowego. Na przykład większość smartfonów posaida GPU(Raspberry Pi również). Możemy otrzymać znaczne przyśpieszenie. TensorFlow Lite może być skonfigurowany z delgacjami aby wykorzystać akcelerację sprzętową. Pozwala to wykonać część operacji na GPU. 

* TensorFlow Lite:
	```python
	import tflite_runtime.interpreter as tflite

	interpreter = tflite.Interpreter(model_path, experimental_delegates=[tflite.load_delegates('libedgetup.so.1')])
	```

##### 4. Optymalizacja modelu
TensorFlow Lite udostępnia optymalizacujące rozmiar i wydajność modeli, często z minimalnym wpływem na dokładność. Zoptymalizowane modele wymagają odrobinę bardziej złożonego trenigu, konwersji i integracji.
* Wydajność
Założenienim jest uzyskanie optymalnej równowagi pomiędzy wydajnością, rozmiarem i skutecznością.
* Kwantyzacja (ang. Quantization)
Poprzez zredukowanie precyzji kwantyzacja może zmniejszyć zarówno rozmiar i czas. TensorFlow Lite może zredukowac precyzję o połowę (float16) lub do 8-bit integers. Kwantyzacja może zostać wykonana poprzez paczkę **TensorFlow**. Przykładowy kod kwantyzacji:
	* TensorFlow
		```python
		import tensorflow as tf

		converter = tf.lite.TFLiteConverter.from_saved_model(model_dir)
		converter.optimizations = [tf.lite.Optimize.DEFAULT]
		tflite_quant_model = converter.convert()
		open("conv_model.tflite", "wb").write(tflite_quant_model)
		```

Aby wykorzystać [TensorFlowLite](https://www.tensorflow.org/lite/guide)  na urządzeniu raspberry PI musimy zainstalować odpowiedni± wersję. Pobrana wersja tak naprawdę udostępnia jedynie interpreter do modeli. Pobranie pełnej wersji TensorFlow, a nie jedynie wersji Lite powodowało błędy (pobierała się wersja 1.x, gdzie aktualna wersja to 2.2):
```
pip install https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_armv7l.whl
```
Oprócz tej głównej biblioteki będziemy potrzebować `numpy` oraz `pillow`. Możemy je zainstalować przy pomocy zamieszczonego pliku `requirements.txt`:
```
pip install - r requirements.txt
```

Przykład wykorzystania rozponowania obrazków:
```
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/python/
```
Aby działało musimy poczynić kilka zmian, ponieważ nie mamy zainstalowanego czystegoTensorflow. W folderze `image_recognition` jest przkeształcony plik z komentarzami opisuj±cymi działanie programu. W tym ktalogu również znajduj± się przekształcony model zapisany w formacie `.tflite`, katalog `images` z przykładowymi obrazki do klasyfikacji oraz znaczniki. Aby uruchomić program należy wykonać:
```
python image_recognition --model_file model.tflite --label_file labels.txt --image cat.png
```
Przykładowy output:
```
0.263747: 286:Egyptian cat
0.263291: 281:grey fox, gray fox, Urocyon cinereoargenteus
0.131645: 392:coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch
0.079361: 105:wallaby, brush kangaroo
0.044219: 278:red fox, Vulpes vulpes
```
Gdzie pierwsza kolumna to jest trafność modelu, a druga to etykiety dopasowania.
